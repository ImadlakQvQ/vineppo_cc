[2024-11-24 18:48:39,647] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-24 18:49:34,896] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-11-24 18:49:34,896] [INFO] [runner.py:568:main] cmd = /lustre06/project/6002409/imadlak/program/VinePPO/venv/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --no_local_rank --enable_each_rank_log=None src/treetune/main.py --configs configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet run_iteration_loop
[2024-11-24 18:49:38,459] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[2024-11-24 18:49:39,961] [INFO] [launch.py:138:main] 0 EBVERSIONNCCL=2.18.3
[2024-11-24 18:49:39,961] [INFO] [launch.py:138:main] 0 EBROOTNCCL=/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/CUDA/gcccore/cuda12.2/nccl/2.18.3
[2024-11-24 18:49:39,961] [INFO] [launch.py:138:main] 0 EBDEVELNCCL=/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/CUDA/gcccore/cuda12.2/nccl/2.18.3/easybuild/x86-64-v3-CUDA-gcccore-cuda12.2-nccl-2.18.3-easybuild-devel
[2024-11-24 18:49:39,961] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-11-24 18:49:39,961] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-11-24 18:49:39,961] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-11-24 18:49:39,961] [INFO] [launch.py:163:main] dist_world_size=4
[2024-11-24 18:49:39,961] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2024-11-24 18:49:39,962] [INFO] [launch.py:253:main] process 2021844 spawned with command: ['/lustre06/project/6002409/imadlak/program/VinePPO/venv/bin/python', '-u', 'src/treetune/main.py', '--configs', 'configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet', 'run_iteration_loop']
[2024-11-24 18:49:39,963] [INFO] [launch.py:253:main] process 2021845 spawned with command: ['/lustre06/project/6002409/imadlak/program/VinePPO/venv/bin/python', '-u', 'src/treetune/main.py', '--configs', 'configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet', 'run_iteration_loop']
[2024-11-24 18:49:39,964] [INFO] [launch.py:253:main] process 2021846 spawned with command: ['/lustre06/project/6002409/imadlak/program/VinePPO/venv/bin/python', '-u', 'src/treetune/main.py', '--configs', 'configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet', 'run_iteration_loop']
[2024-11-24 18:49:39,965] [INFO] [launch.py:253:main] process 2021847 spawned with command: ['/lustre06/project/6002409/imadlak/program/VinePPO/venv/bin/python', '-u', 'src/treetune/main.py', '--configs', 'configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet', 'run_iteration_loop']
[INFO|main.py:59:2021844] 2024-11-24 18:49:43,708 >> Config files: ['configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet']
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >> ----Config----
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >> {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "analyzers": [
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 100,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "{query}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_requests": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "reward_function": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "math_task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "mc_value_prediction",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "vllm_server": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "swap_space": 24
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "actor_deepspeed_config": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "bf16": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "enabled": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "prescale_gradients": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "train_batch_size": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "train_micro_batch_size_per_gpu": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "wall_clock_breakdown": false
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "num_bootstrap_runs": 32,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "num_bootstrap_samples": 32,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "per_device_batch_size": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "store_rolling_aggregates_on_cpu": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "ppo_gradient_variance"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_iterations": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "mc_advantage_distribution"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "alternative_continuation_inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 100,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "num_expansion_rounds": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "{query}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 5,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 100,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "{query}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_requests": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_states": 256,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "min_num_alternative_actions": 3,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "num_mc_rollouts": 9,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "reward_function": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "math_task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "mc_value_action_ranking",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "vllm_server": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "swap_space": 24
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     ],
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "directory": "experiments",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "episode_generator": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "answer_prefix": null,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "append_bos_to_query": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "append_eos_to_response": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "dataset_num_samples_per_iteration": 64,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "dataset_sample_with_replacement": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "dataset_shuffle_on_each_iteration": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "fill_missing_episodes": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_key_name": "text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "identity"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_concurrent_generations": 64,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_concurrent_programs": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_depth": 100,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "no_cache": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "samples": 8,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "initial_model_name_or_path": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "max_question_length": 1512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "max_sequence_length": 2048,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "max_step_for_value_estimation": 25,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "reasoning_step_delimiter": "",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "reward_function": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "math_task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "penalize_unfinished_response": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "math_reward_function",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "unfinished_response_penalty": 0
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "total_num_iterations": 650,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "type": "math_episode_generator_w_mc_advantages",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "value_estimation_inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_key_name": "full_text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_concurrent_generations": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_concurrent_programs": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_depth": 100,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "no_cache": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "question_template": "{query}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "samples": 9,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "vllm_gpu_memory_utilization": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "vllm_min_available_gpu_memory_mb": 10240,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "vllm_server": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_num_seqs": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "swap_space": 8
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "wait_until_memory_release": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "episodes_cloud_log_steps": 50,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "evaluation_vllm_server": {},
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "exp_name": "polIter_rho1bSft2_vineppo_GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "global_vars": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "debug_mode": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "dirs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "data": "data",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "experiments": "experiments"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "seed": 2746318213
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "inference_pipelines": [
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "analyzers": [
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "task_performance"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             ],
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_portion": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_split": "test",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_name": "gsm8k_test",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.35,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "seed": 42,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "prompt_library": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "tree": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "expansion": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "analyzers": [
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "task_performance"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             ],
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_portion": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_split": "validation",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_name": "gsm8k_validation",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.35,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "seed": 42,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "prompt_library": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "tree": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "expansion": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "analyzers": [
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "task_performance"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             ],
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_portion": 0.05253521,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataset_split": "train",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_name": "gsm8k_train",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "inference_strategy": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "answer_extractor": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_key_name": "text",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "identity"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "guidance_llm": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_base": "none",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "caching": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "max_retries": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "max_depth": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "no_cache": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "node_expander": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "program_kwargs": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "temperature": 0.35,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "top_p": 0.9
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_field": "query",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "samples": 16,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "seed": 42,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "cot"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "prompt_library": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "tree": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "expansion": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "task": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "gsm8k",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_original_format": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     ],
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "num_episodes_per_iteration": 512,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "num_iterations": 650,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "prompt_library": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "tree": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "expansion": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "tokenizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "type": "pretrained"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "trainer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "actor_deepspeed_config": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "bf16": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "enabled": "auto"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gradient_clipping": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "optimizer": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "params": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "betas": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "eps": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "lr": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "weight_decay": "auto"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "AdamW"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "scheduler": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "params": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "last_batch_iteration": -1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "total_num_steps": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "warmup_max_lr": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "warmup_min_lr": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                     "warmup_num_steps": "auto"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "type": "WarmupDecayLR"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "zero_allow_untested_optimizer": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "zero_optimization": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "allgather_bucket_size": 500000000,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "allgather_partitions": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "contiguous_gradients": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "overlap_comm": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "reduce_bucket_size": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "reduce_scatter": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "stage": 0
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "actor_model": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "disable_dropout": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "pretrained_args": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "cache_deepspeed_engines": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "critic_deepspeed_config": null,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "critic_model": null,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "general_training_args": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "bf16": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "checkpoint_keep_steps": 40,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataloader_num_workers": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "dataloader_pin_memory": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gradient_accumulation_steps": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gradient_checkpointing": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "learning_rate": 1e-06,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "logging_steps": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "max_grad_norm": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "per_device_train_batch_size": null,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "save_steps": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "seed": 2746318213,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "target_train_batch_size": 64,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "warmup_ratio": 0.03,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "weight_decay": 0
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "move_reference_model_to_cpu": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "num_epochs_per_iteration": 2,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "params": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "adap_kl_ctrl": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "cliprange": 0.2,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "cliprange_value": 0.2,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gamma": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "init_kl_coef": 0.0001,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "kl_penalty_loss_clip_max": 10,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "kl_penalty_loss_clip_min": 0,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "kl_penalty_loss_type": "control_variate",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "lam": 1,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "temperature": 0.6,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "use_score_norm": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "use_score_scaling": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "whiten_advantages": true,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "whiten_rewards": false
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "reference_deepspeed_config": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "bf16": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "enabled": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "prescale_gradients": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "wall_clock_breakdown": false
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "reference_model": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "pretrained_args": {
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "report_entropy": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "save_hf_critic_checkpoint": false,
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>         "type": "ppo"
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     },
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "type": "policy_iteration",
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >>     "use_deepspeed": true
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >> }
[INFO|main.py:60:2021844] 2024-11-24 18:49:43,708 >> --------------
[INFO|main.py:59:2021846] 2024-11-24 18:49:43,709 >> Config files: ['configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet']
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >> ----Config----
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >> {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "analyzers": [
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_requests": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "mc_value_prediction",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "actor_deepspeed_config": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "bf16": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "enabled": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "prescale_gradients": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "train_batch_size": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "train_micro_batch_size_per_gpu": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "wall_clock_breakdown": false
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "num_bootstrap_runs": 32,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "num_bootstrap_samples": 32,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "per_device_batch_size": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "store_rolling_aggregates_on_cpu": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "ppo_gradient_variance"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_iterations": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "mc_advantage_distribution"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "alternative_continuation_inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 5,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_requests": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_states": 256,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "min_num_alternative_actions": 3,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "num_mc_rollouts": 9,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "mc_value_action_ranking",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "directory": "experiments",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "episode_generator": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "answer_prefix": null,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "append_bos_to_query": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "append_eos_to_response": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "dataset_num_samples_per_iteration": 64,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "dataset_sample_with_replacement": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_on_each_iteration": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "fill_missing_episodes": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_key_name": "text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "identity"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 64,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "samples": 8,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "initial_model_name_or_path": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "max_question_length": 1512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "max_sequence_length": 2048,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "max_step_for_value_estimation": 25,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "reasoning_step_delimiter": "",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "reward_function": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "math_task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "penalize_unfinished_response": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "math_reward_function",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "unfinished_response_penalty": 0
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "total_num_iterations": 650,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "type": "math_episode_generator_w_mc_advantages",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "value_estimation_inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_key_name": "full_text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "question_template": "{query}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "samples": 9,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "vllm_gpu_memory_utilization": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "vllm_min_available_gpu_memory_mb": 10240,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "vllm_server": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_num_seqs": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "swap_space": 8
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "wait_until_memory_release": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "episodes_cloud_log_steps": 50,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "evaluation_vllm_server": {},
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "exp_name": "polIter_rho1bSft2_vineppo_GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "global_vars": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "debug_mode": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "dirs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "data": "data",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "experiments": "experiments"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "seed": 2746318213
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "inference_pipelines": [
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_split": "test",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_test",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_split": "validation",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_validation",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_portion": 0.05253521,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataset_split": "train",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_train",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "num_episodes_per_iteration": 512,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "num_iterations": 650,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "prompt_library": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "tree": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "expansion": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "tokenizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "type": "pretrained"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "trainer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "actor_deepspeed_config": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "enabled": "auto"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gradient_clipping": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "optimizer": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "betas": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "eps": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "lr": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "weight_decay": "auto"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "AdamW"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "scheduler": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "last_batch_iteration": -1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "total_num_steps": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "warmup_max_lr": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "warmup_min_lr": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                     "warmup_num_steps": "auto"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "type": "WarmupDecayLR"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "zero_allow_untested_optimizer": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "zero_optimization": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "allgather_bucket_size": 500000000,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "allgather_partitions": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "contiguous_gradients": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "overlap_comm": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "reduce_bucket_size": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "reduce_scatter": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "stage": 0
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "actor_model": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "disable_dropout": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "cache_deepspeed_engines": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "critic_deepspeed_config": null,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "critic_model": null,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "general_training_args": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "bf16": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "checkpoint_keep_steps": 40,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataloader_num_workers": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "dataloader_pin_memory": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gradient_checkpointing": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "learning_rate": 1e-06,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "logging_steps": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "max_grad_norm": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "per_device_train_batch_size": null,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "save_steps": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "seed": 2746318213,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "target_train_batch_size": 64,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "warmup_ratio": 0.03,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "weight_decay": 0
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "move_reference_model_to_cpu": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "num_epochs_per_iteration": 2,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "params": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "adap_kl_ctrl": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "cliprange": 0.2,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "cliprange_value": 0.2,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gamma": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "init_kl_coef": 0.0001,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_max": 10,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_min": 0,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_type": "control_variate",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "lam": 1,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "temperature": 0.6,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "use_score_norm": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "use_score_scaling": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "whiten_advantages": true,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "whiten_rewards": false
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "reference_deepspeed_config": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "enabled": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "prescale_gradients": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "wall_clock_breakdown": false
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "reference_model": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "report_entropy": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "save_hf_critic_checkpoint": false,
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>         "type": "ppo"
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "type": "policy_iteration",
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >>     "use_deepspeed": true
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >> }
[INFO|main.py:60:2021846] 2024-11-24 18:49:43,709 >> --------------
[INFO|main.py:59:2021847] 2024-11-24 18:49:43,709 >> Config files: ['configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet']
[INFO|main.py:59:2021845] 2024-11-24 18:49:43,709 >> Config files: ['configs/polIter_rho1bSft2_vineppo_GSM8K.jsonnet']
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >> ----Config----
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >> {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "analyzers": [
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_requests": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "mc_value_prediction",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "actor_deepspeed_config": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "bf16": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "enabled": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "prescale_gradients": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "train_batch_size": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "train_micro_batch_size_per_gpu": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "wall_clock_breakdown": false
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "num_bootstrap_runs": 32,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "num_bootstrap_samples": 32,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "per_device_batch_size": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "store_rolling_aggregates_on_cpu": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "ppo_gradient_variance"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_iterations": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "mc_advantage_distribution"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "alternative_continuation_inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 5,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_requests": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_states": 256,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "min_num_alternative_actions": 3,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "num_mc_rollouts": 9,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "mc_value_action_ranking",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "directory": "experiments",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "episode_generator": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "answer_prefix": null,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "append_bos_to_query": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "append_eos_to_response": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "dataset_num_samples_per_iteration": 64,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "dataset_sample_with_replacement": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_on_each_iteration": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "fill_missing_episodes": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_key_name": "text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "identity"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 64,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "samples": 8,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "initial_model_name_or_path": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "max_question_length": 1512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "max_sequence_length": 2048,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "max_step_for_value_estimation": 25,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "reasoning_step_delimiter": "",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "reward_function": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "math_task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "penalize_unfinished_response": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "math_reward_function",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "unfinished_response_penalty": 0
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "total_num_iterations": 650,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "type": "math_episode_generator_w_mc_advantages",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "value_estimation_inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_key_name": "full_text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "question_template": "{query}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "samples": 9,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "vllm_gpu_memory_utilization": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "vllm_min_available_gpu_memory_mb": 10240,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "vllm_server": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_num_seqs": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "swap_space": 8
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "wait_until_memory_release": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "episodes_cloud_log_steps": 50,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "evaluation_vllm_server": {},
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "exp_name": "polIter_rho1bSft2_vineppo_GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "global_vars": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "debug_mode": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "dirs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "data": "data",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "experiments": "experiments"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "seed": 2746318213
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "inference_pipelines": [
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_split": "test",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_test",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_split": "validation",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_validation",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_portion": 0.05253521,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataset_split": "train",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_train",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "num_episodes_per_iteration": 512,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "num_iterations": 650,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "prompt_library": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "tree": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "expansion": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "tokenizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "type": "pretrained"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "trainer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "actor_deepspeed_config": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "enabled": "auto"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gradient_clipping": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "optimizer": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "betas": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "eps": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "lr": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "weight_decay": "auto"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "AdamW"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "scheduler": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "last_batch_iteration": -1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "total_num_steps": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "warmup_max_lr": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "warmup_min_lr": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                     "warmup_num_steps": "auto"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "type": "WarmupDecayLR"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "zero_allow_untested_optimizer": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "zero_optimization": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "allgather_bucket_size": 500000000,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "allgather_partitions": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "contiguous_gradients": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "overlap_comm": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "reduce_bucket_size": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "reduce_scatter": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "stage": 0
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "actor_model": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "disable_dropout": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "cache_deepspeed_engines": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "critic_deepspeed_config": null,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "critic_model": null,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "general_training_args": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "bf16": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "checkpoint_keep_steps": 40,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataloader_num_workers": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "dataloader_pin_memory": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gradient_checkpointing": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "learning_rate": 1e-06,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "logging_steps": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "max_grad_norm": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "per_device_train_batch_size": null,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "save_steps": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "seed": 2746318213,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "target_train_batch_size": 64,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "warmup_ratio": 0.03,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "weight_decay": 0
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "move_reference_model_to_cpu": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "num_epochs_per_iteration": 2,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "params": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "adap_kl_ctrl": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "cliprange": 0.2,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "cliprange_value": 0.2,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gamma": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "init_kl_coef": 0.0001,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_max": 10,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_min": 0,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_type": "control_variate",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "lam": 1,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "temperature": 0.6,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "use_score_norm": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "use_score_scaling": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "whiten_advantages": true,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "whiten_rewards": false
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "reference_deepspeed_config": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "enabled": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "prescale_gradients": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "wall_clock_breakdown": false
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "reference_model": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "report_entropy": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "save_hf_critic_checkpoint": false,
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>         "type": "ppo"
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "type": "policy_iteration",
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >>     "use_deepspeed": true
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >> }
[INFO|main.py:60:2021847] 2024-11-24 18:49:43,709 >> --------------
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >> ----Config----
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >> {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "analyzers": [
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_requests": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "mc_value_prediction",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "actor_deepspeed_config": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "bf16": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "enabled": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "prescale_gradients": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "train_batch_size": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "train_micro_batch_size_per_gpu": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "wall_clock_breakdown": false
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "num_bootstrap_runs": 32,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "num_bootstrap_samples": 32,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "per_device_batch_size": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "store_rolling_aggregates_on_cpu": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "ppo_gradient_variance"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_iterations": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "mc_advantage_distribution"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "alternative_continuation_inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 5,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "full_text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 100,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "num_expansion_rounds": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "{query}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_checkpoints": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_requests": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_states": 256,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "min_num_alternative_actions": 3,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "num_mc_rollouts": 9,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "reward_function": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "math_task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "penalize_unfinished_response": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "math_reward_function",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "unfinished_response_penalty": 0
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "mc_value_action_ranking",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "vllm_server": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "enable_prefix_caching": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "swap_space": 24
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "directory": "experiments",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "episode_generator": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "answer_prefix": null,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "append_bos_to_query": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "append_eos_to_response": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "dataset_num_samples_per_iteration": 64,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "dataset_sample_with_replacement": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "dataset_shuffle_on_each_iteration": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "fill_missing_episodes": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_key_name": "text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "identity"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 64,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "samples": 8,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "initial_model_name_or_path": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "max_question_length": 1512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "max_sequence_length": 2048,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "max_step_for_value_estimation": 25,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "reasoning_step_delimiter": "",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "reward_function": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "math_task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "penalize_unfinished_response": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "math_reward_function",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "unfinished_response_penalty": 0
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "total_num_iterations": 650,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "type": "math_episode_generator_w_mc_advantages",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "value_estimation_inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_key_name": "full_text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "solution_prefix": "\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "identity_with_solution_prefix"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "model": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_concurrent_generations": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_concurrent_programs": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_depth": 100,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "no_cache": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "question_template": "{query}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "samples": 9,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "vllm_gpu_memory_utilization": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "vllm_min_available_gpu_memory_mb": 10240,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "vllm_server": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_num_seqs": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "swap_space": 8
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "wait_until_memory_release": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "episodes_cloud_log_steps": 50,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "evaluation_vllm_server": {},
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "exp_name": "polIter_rho1bSft2_vineppo_GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "global_vars": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "debug_mode": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "dirs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "data": "data",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "experiments": "experiments"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "seed": 2746318213
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "inference_pipelines": [
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_split": "test",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_test",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_portion": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_split": "validation",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_validation",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "analyzers": [
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "task_performance"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             ],
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_portion": 0.05253521,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_shuffle_before_portion": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataset_split": "train",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_name": "gsm8k_train",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "inference_strategy": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "answer_extractor": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_key_name": "text",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "identity"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "guidance_llm": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_base": "none",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "api_key": "EMPTY",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "caching": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_calls_per_min": 1000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "max_retries": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "openai_vllm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_generations": 128,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_concurrent_programs": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "max_depth": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "no_cache": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "node_expander": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "model_context_size": 2047,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "node_text_template": "{chain_of_thought}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "program_kwargs": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "max_tokens": 1024,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "stop": "\"\n\n\nProblem:\"",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "temperature": 0.35,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "top_p": 0.9
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "hf_model_name": "microsoft/rho-math-1b-v0.1",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "type": "efficient_iid"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_field": "query",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "samples": 16,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "seed": 42,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "cot"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "prompt_library": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "tree": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "expansion": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                         "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "task": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "dataset_dict_path": "data/gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "load_dataset_dict": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "remove_calculator_expressions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "gsm8k",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_original_format": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     ],
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "num_episodes_per_iteration": 512,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "num_iterations": 650,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "prompt_library": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "tree": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "expansion": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "iid": "{{prefix}}{{gen \"chain_of_thought\" temperature={temperature} top_p={top_p} max_tokens={max_tokens} seed={seed} save_stop_text=\"stop_text\" stop={stop} n={num_samples}}}"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "question_template": "[MATH_TASK] Problem:\n{query}\n\nSolution:"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "tokenizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "type": "pretrained"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "trainer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "actor_deepspeed_config": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "enabled": "auto"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gradient_clipping": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "optimizer": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "betas": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "eps": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "lr": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "weight_decay": "auto"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "AdamW"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "scheduler": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "params": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "last_batch_iteration": -1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "total_num_steps": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "warmup_max_lr": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "warmup_min_lr": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                     "warmup_num_steps": "auto"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "type": "WarmupDecayLR"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "zero_allow_untested_optimizer": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "zero_optimization": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "allgather_bucket_size": 500000000,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "allgather_partitions": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "contiguous_gradients": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "overlap_comm": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "reduce_bucket_size": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "reduce_scatter": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "stage": 0
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "actor_model": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "disable_dropout": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "cache_deepspeed_engines": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "critic_deepspeed_config": null,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "critic_model": null,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "general_training_args": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "bf16": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "checkpoint_keep_steps": 40,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataloader_num_workers": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "dataloader_pin_memory": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gradient_checkpointing": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "learning_rate": 1e-06,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "logging_steps": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "max_grad_norm": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "per_device_train_batch_size": null,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "save_steps": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "seed": 2746318213,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "target_train_batch_size": 64,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "warmup_ratio": 0.03,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "weight_decay": 0
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "move_reference_model_to_cpu": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "num_epochs_per_iteration": 2,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "params": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "adap_kl_ctrl": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "cliprange": 0.2,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "cliprange_value": 0.2,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gamma": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "init_kl_coef": 0.0001,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_max": 10,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_clip_min": 0,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "kl_penalty_loss_type": "control_variate",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "lam": 1,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "temperature": 0.6,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "use_score_norm": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "use_score_scaling": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "whiten_advantages": true,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "whiten_rewards": false
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "reference_deepspeed_config": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "bf16": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "enabled": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "gradient_accumulation_steps": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "prescale_gradients": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "train_batch_size": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "train_micro_batch_size_per_gpu": "auto",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "wall_clock_breakdown": false
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "reference_model": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "hf_model_name": "realtreetune/rho-1b-sft-GSM8K",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "pretrained_args": {
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>                 "use_flash_attention_2": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>             "type": "pretrained_causal_lm"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "report_entropy": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "save_hf_critic_checkpoint": false,
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>         "type": "ppo"
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     },
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "type": "policy_iteration",
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >>     "use_deepspeed": true
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >> }
[INFO|main.py:60:2021845] 2024-11-24 18:49:43,709 >> --------------
[2024-11-24 18:50:42,382] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-24 18:50:42,385] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-24 18:50:42,393] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-24 18:50:42,395] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.



[93m [WARNING] [0m async_io: please install the libaio-devel package with yum[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.

[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH



[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH

[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-11-24 18:51:52,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-24 18:51:52,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-24 18:51:52,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-24 18:51:52,667] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-24 18:51:52,667] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[INFO|base_runtime.py:202:2021844] 2024-11-24 18:51:53,058 >> Setting seed = 2746318213
[INFO|base_runtime.py:202:2021847] 2024-11-24 18:51:53,478 >> Setting seed = 2746318213
[INFO|base_runtime.py:202:2021846] 2024-11-24 18:51:53,516 >> Setting seed = 2746318213
[INFO|base_runtime.py:202:2021845] 2024-11-24 18:51:53,516 >> Setting seed = 2746318213
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2.
wandb: Tracking run with wandb version 0.16.3
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Device: 0
Device: 1
Device: 2
Device: 3
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >> GPUs Info: 
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >> [
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     {
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "name": "NVIDIA A100-SXM4-40GB",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "capability": [
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             8,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         ],
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cores": 108,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cuda_core": "unknown",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "threads": 221184,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "clock": 1410.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "memory_clock": 1215.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "total_memory": 4095.9999990463257,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "free_memory": 3922.0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     },
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     {
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "name": "NVIDIA A100-SXM4-40GB",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "capability": [
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             8,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         ],
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cores": 108,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cuda_core": "unknown",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "threads": 221184,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "clock": 1410.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "memory_clock": 1215.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "total_memory": 4095.9999990463257,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "free_memory": 3922.0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     },
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     {
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "name": "NVIDIA A100-SXM4-40GB",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "capability": [
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             8,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         ],
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cores": 108,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cuda_core": "unknown",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "threads": 221184,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "clock": 1410.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "memory_clock": 1215.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "total_memory": 4095.9999990463257,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "free_memory": 3922.0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     },
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     {
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "name": "NVIDIA A100-SXM4-40GB",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "capability": [
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             8,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>             0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         ],
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cores": 108,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "cuda_core": "unknown",
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "threads": 221184,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "clock": 1410.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "memory_clock": 1215.0,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "total_memory": 4095.9999990463257,
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>         "free_memory": 3922.0
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >>     }
[INFO|base_runtime.py:78:2021844] 2024-11-24 18:51:57,434 >> ]
[INFO|base_runtime.py:93:2021844] 2024-11-24 18:51:57,601 >> Application ENV: APP_SEED=2746318213
wandb: WARNING Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 18:51:59,467 >> Using default temp_dir_root: experiments/polIter_rho1bSft2_vineppo_GSM8K/temp_episodes
[INFO|on_policy_episode_generator.py:122:2021844] 2024-11-24 18:52:01,470 >> Found free ports: [28206, 62405, 19317, 47648]
[INFO|on_policy_episode_generator.py:132:2021844] 2024-11-24 18:52:01,735 >> Rank 0 using vLLM port 28206
[INFO|on_policy_episode_generator.py:132:2021845] 2024-11-24 18:52:01,793 >> Rank 1 using vLLM port 62405
[INFO|on_policy_episode_generator.py:132:2021847] 2024-11-24 18:52:01,793 >> Rank 3 using vLLM port 47648
[INFO|on_policy_episode_generator.py:132:2021846] 2024-11-24 18:52:01,794 >> Rank 2 using vLLM port 19317
[ERROR|math_episode_generator.py:92:2021846] 2024-11-24 19:36:05,248 >> Failed to load BLEU metric: Couldn't find a module script at /lustre06/project/6002409/imadlak/program/VinePPO/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either.
[ERROR|math_episode_generator.py:92:2021844] 2024-11-24 19:36:05,268 >> Failed to load BLEU metric: Couldn't find a module script at /lustre06/project/6002409/imadlak/program/VinePPO/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either.
[ERROR|math_episode_generator.py:92:2021847] 2024-11-24 19:36:05,268 >> Failed to load BLEU metric: Couldn't find a module script at /lustre06/project/6002409/imadlak/program/VinePPO/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either.
[INFO|ppo_trainer.py:310:2021844] 2024-11-24 19:36:05,270 >> Per device batch size: 16
[INFO|ppo_trainer.py:311:2021844] 2024-11-24 19:36:05,270 >> Gradient accumulation steps: 1
[INFO|ppo_trainer.py:314:2021844] 2024-11-24 19:36:05,270 >> Num of total processes: 4
[INFO|ppo_trainer.py:315:2021844] 2024-11-24 19:36:05,271 >> Global batch size (w. parallel, distributed & accumulation): 64
[INFO|ppo_trainer.py:318:2021844] 2024-11-24 19:36:05,271 >> Total number of training steps (Gradient Updates): 10400
[INFO|ppo_trainer.py:188:2021844] 2024-11-24 19:36:05,271 >> No critic model provided. We then assume values are provided in the episodes.
[INFO|ppo_trainer.py:229:2021844] 2024-11-24 19:36:05,271 >> No temporary checkpoint directory provided. Using /lustre06/project/6002409/imadlak/program/VinePPO/temp_ppo_checkpoints
[INFO|policy_iteration_runtime.py:217:2021844] 2024-11-24 19:36:05,292 >> ********************************************************************************
[INFO|policy_iteration_runtime.py:218:2021844] 2024-11-24 19:36:05,292 >> Running iteration 0
[INFO|policy_iteration_runtime.py:219:2021844] 2024-11-24 19:36:05,293 >> ********************************************************************************
[ERROR|math_episode_generator.py:92:2021845] 2024-11-24 19:36:05,546 >> Failed to load BLEU metric: Couldn't find a module script at /lustre06/project/6002409/imadlak/program/VinePPO/bleu/bleu.py. Module 'bleu' doesn't exist on the Hugging Face Hub either.
[INFO|policy_iteration_runtime.py:731:2021844] 2024-11-24 19:36:05,549 >> --------------------------------------------------------------------------------
[INFO|policy_iteration_runtime.py:732:2021844] 2024-11-24 19:36:05,549 >> Episode at 0 does not exist. Generating episodes...
[INFO|policy_iteration_runtime.py:735:2021844] 2024-11-24 19:36:05,549 >> --------------------------------------------------------------------------------
[INFO|on_policy_episode_generator.py:213:2021847] 2024-11-24 19:36:05,703 >> Need at least 10240. Waiting for GPU3 used memory to be below 30086.375 MB. Total GPU memory: 40326.375 MB.
[INFO|on_policy_episode_generator.py:213:2021846] 2024-11-24 19:36:05,703 >> Need at least 10240. Waiting for GPU2 used memory to be below 30086.375 MB. Total GPU memory: 40326.375 MB.
[INFO|on_policy_episode_generator.py:213:2021845] 2024-11-24 19:36:05,704 >> Need at least 10240. Waiting for GPU1 used memory to be below 30086.375 MB. Total GPU memory: 40326.375 MB.
[INFO|on_policy_episode_generator.py:213:2021844] 2024-11-24 19:36:05,707 >> Need at least 10240. Waiting for GPU0 used memory to be below 30086.375 MB. Total GPU memory: 40326.375 MB.
[INFO|gpu_utils.py:236:2021844] 2024-11-24 19:36:05,761 >> GPU 0 has less than 30086.375 MB used. Continuing...
[INFO|gpu_utils.py:236:2021847] 2024-11-24 19:36:05,781 >> GPU 3 has less than 30086.375 MB used. Continuing...
[INFO|gpu_utils.py:236:2021846] 2024-11-24 19:36:05,782 >> GPU 2 has less than 30086.375 MB used. Continuing...
[INFO|gpu_utils.py:236:2021845] 2024-11-24 19:36:05,782 >> GPU 1 has less than 30086.375 MB used. Continuing...
[2024-11-24 19:36:05,964] [INFO] [utils.py:772:see_memory_usage] Before generating episodes
[2024-11-24 19:36:05,965] [INFO] [utils.py:773:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2024-11-24 19:36:05,965] [INFO] [utils.py:780:see_memory_usage] CPU Virtual Memory:  used = 19.79 GB, percent = 3.9%
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,220 >> Initial Dataset Size: 7100
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,395 >> Filtered out 0 long questions from 7100 questions.
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,434 >> Dataset Size(portion=None): 64
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >> Dataset Examples: [
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>   {
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_final_answer": "90",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_solution": "He spent $2.00 on seeds and $8.00 on soil for a total of 2+8 = $10.00\nHe sells each of the 20 basil plants for $5.00 so he makes 20*5 = $100.00\nHe made $100.00 from selling basil plants and he spent $10.00 to buy and grow the seeds. His net profit is 100-10 = $90.00",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_treetune__idx": 4768,
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "answer": "90",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "answer_without_calculator": "He spent $2.00 on seeds and $8.00 on soil for a total of 2+8 = $10.00\nHe sells each of the 20 basil plants for $5.00 so he makes 20*5 = $100.00\nHe made $100.00 from selling basil plants and he spent $10.00 to buy and grow the seeds. His net profit is 100-10 = $90.00\n#### 90",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "problem": "Burt spent $2.00 on a packet of basil seeds and $8.00 on potting soil.  The packet of seeds yielded 20 basil plants.  He sells each basil plant for $5.00 at the local farmer's market.  What is the net profit from his basil plants?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "query": "Burt spent $2.00 on a packet of basil seeds and $8.00 on potting soil.  The packet of seeds yielded 20 basil plants.  He sells each basil plant for $5.00 at the local farmer's market.  What is the net profit from his basil plants?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "question": "Burt spent $2.00 on a packet of basil seeds and $8.00 on potting soil.  The packet of seeds yielded 20 basil plants.  He sells each basil plant for $5.00 at the local farmer's market.  What is the net profit from his basil plants?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "solution": "He spent $2.00 on seeds and $8.00 on soil for a total of 2+8 = $10.00\nHe sells each of the 20 basil plants for $5.00 so he makes 20*5 = $100.00\nHe made $100.00 from selling basil plants and he spent $10.00 to buy and grow the seeds. His net profit is 100-10 = $90.00\n#### 90"
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>   },
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>   {
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_final_answer": "95",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_solution": "Two fifths of $500 is (2/5)*$500 = $200\nShe needed $200 more than $500 which is $200+ $500 = $700\n15% of $700 is (15/100)*$700 = $105\nShe was given a $105 discount so she has to pay $700-$105 = $595\nShe would still need $595-$500= $95",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "_treetune__idx": 871,
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "answer": "95",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "answer_without_calculator": "Two fifths of $500 is (2/5)*$500 = $200\nShe needed $200 more than $500 which is $200+ $500 = $700\n15% of $700 is (15/100)*$700 = $105\nShe was given a $105 discount so she has to pay $700-$105 = $595\nShe would still need $595-$500= $95\n#### 95",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "problem": "Mrs. Smith wanted to buy wears worth $500. She went to a boutique with the $500 but by the time she had picked out everything she liked, she realized that she would need two-fifths more money than she had. If the shop owner gave her a discount of 15%, how much more money will she still need?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "query": "Mrs. Smith wanted to buy wears worth $500. She went to a boutique with the $500 but by the time she had picked out everything she liked, she realized that she would need two-fifths more money than she had. If the shop owner gave her a discount of 15%, how much more money will she still need?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "question": "Mrs. Smith wanted to buy wears worth $500. She went to a boutique with the $500 but by the time she had picked out everything she liked, she realized that she would need two-fifths more money than she had. If the shop owner gave her a discount of 15%, how much more money will she still need?",
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>     "solution": "Two fifths of $500 is (2/5)*$500 = $200\nShe needed $200 more than $500 which is $200+ $500 = $700\n15% of $700 is (15/100)*$700 = $105\nShe was given a $105 discount so she has to pay $700-$105 = $595\nShe would still need $595-$500= $95\n#### 95"
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >>   }
[INFO|on_policy_episode_generator.py:138:2021844] 2024-11-24 19:36:08,441 >> ]
Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 894.23 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 886.44 examples/s]
Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 1708.00 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 1700.73 examples/s]
Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 980.99 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 978.53 examples/s]
Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 928.00 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 925.90 examples/s]
[INFO|on_policy_episode_generator.py:122:2021844] 2024-11-24 19:36:10,574 >> Found free ports: [4779, 60991, 57413, 8417]
[INFO|on_policy_episode_generator.py:132:2021846] 2024-11-24 19:36:10,730 >> Rank 2 using vLLM port 57413
[INFO|on_policy_episode_generator.py:132:2021845] 2024-11-24 19:36:10,732 >> Rank 1 using vLLM port 60991
[INFO|on_policy_episode_generator.py:132:2021844] 2024-11-24 19:36:10,735 >> Rank 0 using vLLM port 4779
[INFO|on_policy_episode_generator.py:132:2021847] 2024-11-24 19:36:10,740 >> Rank 3 using vLLM port 8417
[INFO|on_policy_episode_generator.py:508:2021845] 2024-11-24 19:36:10,808 >> GPU #1 Auto-computed vLLM GPU memory utilization: 0.87. Currently Allocated: 1499 MB, Total: 40326.375 MB, Remaining: 34944.637500000004 MB.
#####################################################################################
 # Sample Trajectories from the current policy 从当前策略采样
 #####################################################################################

[INFO|math_episode_generator_with_mc_advantages.py:72:2021845] 2024-11-24 19:36:10,808 >> Always generating from scratch
[INFO|on_policy_episode_generator.py:518:2021845] 2024-11-24 19:36:10,808 >> Rank #1 starting vLLM: model=realtreetune/rho-1b-sft-GSM8K   port=60991   seed=2746318313
[INFO|on_policy_episode_generator.py:508:2021844] 2024-11-24 19:36:10,809 >> GPU #0 Auto-computed vLLM GPU memory utilization: 0.87. Currently Allocated: 1353 MB, Total: 40326.375 MB, Remaining: 35076.0375 MB.
#####################################################################################
 # Sample Trajectories from the current policy 从当前策略采样
 #####################################################################################

[INFO|math_episode_generator_with_mc_advantages.py:72:2021844] 2024-11-24 19:36:10,811 >> Always generating from scratch
[INFO|on_policy_episode_generator.py:518:2021844] 2024-11-24 19:36:10,811 >> Rank #0 starting vLLM: model=realtreetune/rho-1b-sft-GSM8K   port=4779   seed=2746318213
[INFO|on_policy_episode_generator.py:508:2021846] 2024-11-24 19:36:10,813 >> GPU #2 Auto-computed vLLM GPU memory utilization: 0.87. Currently Allocated: 1499 MB, Total: 40326.375 MB, Remaining: 34944.637500000004 MB.
#####################################################################################
 # Sample Trajectories from the current policy 从当前策略采样
 #####################################################################################

[INFO|math_episode_generator_with_mc_advantages.py:72:2021846] 2024-11-24 19:36:10,813 >> Always generating from scratch
[INFO|on_policy_episode_generator.py:518:2021846] 2024-11-24 19:36:10,813 >> Rank #2 starting vLLM: model=realtreetune/rho-1b-sft-GSM8K   port=57413   seed=2746318413
[INFO|on_policy_episode_generator.py:508:2021847] 2024-11-24 19:36:10,821 >> GPU #3 Auto-computed vLLM GPU memory utilization: 0.87. Currently Allocated: 1427 MB, Total: 40326.375 MB, Remaining: 35009.4375 MB.
#####################################################################################
 # Sample Trajectories from the current policy 从当前策略采样
 #####################################################################################

[INFO|math_episode_generator_with_mc_advantages.py:72:2021847] 2024-11-24 19:36:10,821 >> Always generating from scratch
[INFO|on_policy_episode_generator.py:518:2021847] 2024-11-24 19:36:10,821 >> Rank #3 starting vLLM: model=realtreetune/rho-1b-sft-GSM8K   port=8417   seed=2746318513
[INFO|vllm_server.py:243:2021847] 2024-11-24 19:36:10,978 >> Server started with PID 2043528 on port 8417
[INFO|vllm_server.py:243:2021846] 2024-11-24 19:36:10,978 >> Server started with PID 2043526 on port 57413
[INFO|vllm_server.py:243:2021844] 2024-11-24 19:36:10,979 >> Server started with PID 2043527 on port 4779
[INFO|vllm_server.py:243:2021845] 2024-11-24 19:36:10,981 >> Server started with PID 2043529 on port 60991
[ERROR|vllm_server.py:207:2021845] 2024-11-24 19:39:06,575 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021847] 2024-11-24 19:39:06,575 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021846] 2024-11-24 19:39:06,575 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021844] 2024-11-24 19:39:06,575 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:150] args: Namespace(host='0.0.0.0', port=57413, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318413, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:37:34 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318413)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> ERROR 11-24 19:38:15 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:18 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     raise err
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     raise new_e
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     conn.connect()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14bb5f33de40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14bb5f33de40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     engine = cls(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return method(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14bb5f33de40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: bacf6967-0e55-4d4c-ba18-7ae1341a479f)')
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:150] args: Namespace(host='0.0.0.0', port=8417, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318513, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:37:34 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318513)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> ERROR 11-24 19:38:15 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:18 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     raise err
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     raise new_e
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     conn.connect()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x15190a0c1e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15190a0c1e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     engine = cls(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return method(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15190a0c1e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: c36c9652-756d-4802-8d3b-7baaecddf55e)')
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:150] args: Namespace(host='0.0.0.0', port=60991, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318313, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:37:34 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318313)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> ERROR 11-24 19:38:15 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:18 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     raise err
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     raise new_e
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     conn.connect()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x153b9a359e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x153b9a359e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     engine = cls(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return method(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x153b9a359e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 5bc69215-d5b1-4f80-bb3a-db62ebd7c7d4)')
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:36:54 api_server.py:150] args: Namespace(host='0.0.0.0', port=4779, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318213, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:37:34 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318213)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> ERROR 11-24 19:38:15 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:15 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> INFO 11-24 19:38:18 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     raise err
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     raise new_e
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     conn.connect()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14f7cc285e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14f7cc285e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     engine = cls(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return method(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14f7cc285e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 047be4d4-76a3-44e7-a46c-058ebffa0a98)')
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:39:06,577 >> 
[ERROR|vllm_server.py:207:2021846] 2024-11-24 19:41:16,008 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021844] 2024-11-24 19:41:16,008 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021847] 2024-11-24 19:41:16,009 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021845] 2024-11-24 19:41:16,010 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:150] args: Namespace(host='0.0.0.0', port=57413, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318413, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:51 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318413)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> ERROR 11-24 19:40:31 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:32 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     raise err
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     raise new_e
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     conn.connect()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x15385097de40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15385097de40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     engine = cls(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return method(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15385097de40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: fe052274-abeb-41e3-b77a-a4e318b867c1)')
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:150] args: Namespace(host='0.0.0.0', port=8417, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318513, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:51 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318513)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> ERROR 11-24 19:40:31 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:32 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     raise err
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     raise new_e
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     conn.connect()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x145fee015e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x145fee015e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     engine = cls(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return method(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x145fee015e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 7333b336-87e4-4dff-942b-fdba601257f3)')
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:150] args: Namespace(host='0.0.0.0', port=60991, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318313, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:51 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318313)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> ERROR 11-24 19:40:31 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:32 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     raise err
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     raise new_e
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     conn.connect()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14fd6c819e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14fd6c819e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     engine = cls(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return method(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14fd6c819e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 94d2e68b-d59f-49c2-9c91-6de61cd33d03)')
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:11 api_server.py:150] args: Namespace(host='0.0.0.0', port=4779, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318213, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:39:51 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318213)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> ERROR 11-24 19:40:31 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:31 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> INFO 11-24 19:40:32 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     raise err
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     raise new_e
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     conn.connect()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14884f1f9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14884f1f9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     engine = cls(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return method(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14884f1f9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: fe506130-0fc4-4fad-9656-b06b414f3ef3)')
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:41:16,011 >> 
[ERROR|vllm_server.py:207:2021847] 2024-11-24 19:43:25,440 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021845] 2024-11-24 19:43:25,441 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021844] 2024-11-24 19:43:25,442 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:150] args: Namespace(host='0.0.0.0', port=60991, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318313, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:00 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318313)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> ERROR 11-24 19:42:40 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:41 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     raise err
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     raise new_e
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     conn.connect()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x153c7bfade40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x153c7bfade40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     engine = cls(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return method(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x153c7bfade40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: a14fb035-4d57-48b5-9a22-e3f4bc6385c4)')
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:150] args: Namespace(host='0.0.0.0', port=8417, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318513, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:00 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318513)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> ERROR 11-24 19:42:40 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:41 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     raise err
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     raise new_e
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     conn.connect()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x148bb9c61e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x148bb9c61e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     engine = cls(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return method(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x148bb9c61e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: b580543d-9a27-4bb1-86cf-e3edada2a689)')
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:41:20 api_server.py:150] args: Namespace(host='0.0.0.0', port=4779, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318213, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:00 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318213)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> ERROR 11-24 19:42:40 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:40 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> INFO 11-24 19:42:41 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     raise err
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     raise new_e
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     conn.connect()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x145c9dd45e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x145c9dd45e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     engine = cls(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return method(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x145c9dd45e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: b9e5b75c-2ac5-44f7-8caf-6917f895967d)')
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:43:25,443 >> 
[ERROR|vllm_server.py:207:2021846] 2024-11-24 19:43:25,443 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:41:20 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:41:20 api_server.py:150] args: Namespace(host='0.0.0.0', port=57413, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318413, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:42:00 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318413)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> ERROR 11-24 19:42:40 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:42:40 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:42:40 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> INFO 11-24 19:42:41 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     raise err
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     raise new_e
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     conn.connect()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x147b46591e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x147b46591e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     engine = cls(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return method(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x147b46591e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: a5a0be49-1e2a-47b1-8e35-4f418ee2197c)')
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:43:25,444 >> 
[ERROR|vllm_server.py:207:2021845] 2024-11-24 19:45:34,872 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:207:2021847] 2024-11-24 19:45:34,872 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:43:29 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:43:29 api_server.py:150] args: Namespace(host='0.0.0.0', port=60991, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318313, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:09 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318313)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> ERROR 11-24 19:44:50 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     raise err
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     raise new_e
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     conn.connect()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14fda11d5e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14fda11d5e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     engine = cls(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return method(
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14fda11d5e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 5aa659b4-9f4d-4231-9c07-56399ade78d5)')
[ERROR|vllm_server.py:211:2021845] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:43:29 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:43:29 api_server.py:150] args: Namespace(host='0.0.0.0', port=8417, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318513, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:09 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318513)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> ERROR 11-24 19:44:50 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> INFO 11-24 19:44:50 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     raise err
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     raise new_e
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     conn.connect()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x151c1dddde40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x151c1dddde40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     engine = cls(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return method(
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x151c1dddde40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: ac7d09a9-6333-4dbe-8cf6-e7c9758f4985)')
[ERROR|vllm_server.py:211:2021847] 2024-11-24 19:45:34,872 >> 
[ERROR|vllm_server.py:207:2021846] 2024-11-24 19:45:34,873 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:43:29 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:43:29 api_server.py:150] args: Namespace(host='0.0.0.0', port=57413, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318413, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:44:09 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318413)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> ERROR 11-24 19:44:50 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:44:50 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:44:50 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> INFO 11-24 19:44:50 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     raise err
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     raise new_e
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     conn.connect()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x149087f05e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x149087f05e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     engine = cls(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return method(
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x149087f05e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 9a3f8f79-095b-4481-be3c-2aa523b488d2)')
[ERROR|vllm_server.py:211:2021846] 2024-11-24 19:45:34,874 >> 
[ERROR|vllm_server.py:207:2021844] 2024-11-24 19:45:34,875 >> vLLM process has exited. Restarting...
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> vLLM Server log:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:43:29 api_server.py:149] vLLM API server version 0.4.0.post1
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:43:29 api_server.py:150] args: Namespace(host='0.0.0.0', port=4779, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='realtreetune/rho-1b-sft-GSM8K', tokenizer=None, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='bfloat16', kv_cache_dtype='auto', max_model_len=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=2746318213, swap_space=8, gpu_memory_utilization=0.87, forced_num_gpu_blocks=None, max_num_batched_tokens=None, max_num_seqs=512, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, engine_use_ray=False, disable_log_requests=False, max_log_len=None)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> /lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   warnings.warn(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:44:09 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='realtreetune/rho-1b-sft-GSM8K', tokenizer='realtreetune/rho-1b-sft-GSM8K', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=2746318213)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> ERROR 11-24 19:44:50 pynccl.py:53] Failed to load NCCL library from libnccl.so.2 .It is expected if you are not running on NVIDIA/AMD GPUs.Otherwise please set the environment variable VLLM_NCCL_SO_PATH to point to the correct nccl library path.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:44:50 pynccl_utils.py:17] Failed to import NCCL library: libnccl.so.2: cannot open shared object file: No such file or directory
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:44:50 pynccl_utils.py:18] It is expected if you are not running on NVIDIA GPUs.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> INFO 11-24 19:44:50 selector.py:16] Using FlashAttention backend.
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     sock = connection.create_connection(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     raise err
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     sock.connect(sa)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> OSError: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     response = self._make_request(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 490, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     raise new_e
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 466, in _make_request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self._validate_conn(conn)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1095, in _validate_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     conn.connect()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 693, in connect
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.sock = sock = self._new_conn()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     raise NewConnectionError(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x14c12e4e9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> The above exception was the direct cause of the following exception:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     resp = conn.urlopen(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     retries = retries.increment(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14c12e4e9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> During handling of the above exception, another exception occurred:
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> Traceback (most recent call last):
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return _run_code(code, main_globals, None,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.10.13/lib/python3.10/runpy.py", line 86, in _run_code
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     exec(code, run_globals)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 157, in <module>
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     engine = AsyncLLMEngine.from_engine_args(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 348, in from_engine_args
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     engine = cls(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 311, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.engine = self._init_engine(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py", line 422, in _init_engine
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return engine_class(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 110, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.model_executor = executor_class(model_config, cache_config,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 37, in __init__
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self._init_worker()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/executor/gpu_executor.py", line 66, in _init_worker
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.driver_worker.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/worker.py", line 107, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.model_runner.load_model()
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/worker/model_runner.py", line 95, in load_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self.model = get_model(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/model_loader.py", line 101, in get_model
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     model.load_weights(model_config.model, model_config.download_dir,
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/models/llama.py", line 377, in load_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     for name, loaded_weight in hf_model_weights_iterator(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 224, in hf_model_weights_iterator
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     hf_folder, hf_weights_files, use_safetensors = prepare_hf_model_weights(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/vllm/model_executor/weight_utils.py", line 168, in prepare_hf_model_weights
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     file_list = fs.ls(model_name_or_path, detail=False, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 280, in ls
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     resolved_path = self.resolve_path(path, revision=revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 186, in resolve_path
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 121, in _repo_and_revision_exist
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     self._api.repo_info(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2756, in repo_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return method(
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return fn(*args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 2540, in model_info
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     r = get_session().get(path, headers=headers, timeout=timeout, params=params)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 602, in get
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return self.request("GET", url, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     resp = self.send(prep, **send_kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     r = adapter.send(request, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     return super().send(request, *args, **kwargs)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>   File "/lustre06/project/6002409/imadlak/program/VinePPO/venv/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >>     raise ConnectionError(e, request=request)
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> requests.exceptions.ConnectionError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/realtreetune/rho-1b-sft-GSM8K (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14c12e4e9e40>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: e5b898ed-e504-4ef7-ab82-80e6361174ac)')
[ERROR|vllm_server.py:211:2021844] 2024-11-24 19:45:34,876 >> 
slurmstepd: error: *** JOB 37230718 ON ng30908 CANCELLED AT 2024-11-25T00:47:41 DUE TO TIME LIMIT ***
